{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset from array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21, 22, -108, 31, -1, 32, 34, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a TensorFlow Dataset from a Python list\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default each element of `tf.data.Dataset` is a `tensor`. We can convert tensors to numpy arrays using the method `.numpy()` or by iterating over numpy arrays using `as_numpy_iterator()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n",
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor(34, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Iterating over dataset\n",
    "for sales in tf_dataset:\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# Iterating using as_numpy_iterator()\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Take first 3\n",
    "for sales in tf_dataset.take(3):\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# Filter\n",
    "tf_dataset = tf_dataset.filter(lambda x: x > 0)\n",
    "\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "44\n",
      "62\n",
      "64\n",
      "68\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# Map\n",
    "tf_dataset = tf_dataset.map(lambda x: x*2)\n",
    "\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "64\n",
      "44\n",
      "62\n",
      "68\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "tf_dataset = tf_dataset.shuffle(3)\n",
    "\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([62 44], shape=(2,), dtype=int32)\n",
      "tf.Tensor([68 62], shape=(2,), dtype=int32)\n",
      "tf.Tensor([64 42], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Batch\n",
    "for sales in tf_dataset.batch(2):\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42 64]\n",
      "[62 44]\n",
      "[68 62]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "\n",
    "tf_dataset = tf_dataset.filter(lambda x: x > 0).map(lambda y: y*2).shuffle(3).batch(2)\n",
    "\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\funny\\\\FB_IMG_1625754072977.jpg'\n",
      "b'images\\\\funny\\\\FB_IMG_1625907625802.jpg'\n",
      "b'images\\\\funny\\\\FB_IMG_1626020773653.jpg'\n",
      "b'images\\\\funny\\\\FB_IMG_1626766662431.jpg'\n",
      "b'images\\\\funny\\\\Screenshot_20210907_170655.jpg'\n"
     ]
    }
   ],
   "source": [
    "# Stores image files, doesn't load them into memory yet\n",
    "images_ds = tf.data.Dataset.list_files('images/*/*', shuffle=False)\n",
    "\n",
    "for file in images_ds.take(5):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\funny\\\\Screenshot_20211114_130621.jpg'\n",
      "b'images\\\\not_funny\\\\Screenshot_20220227_143451.jpg'\n",
      "b'images\\\\funny\\\\FB_IMG_1626766662431.jpg'\n",
      "b'images\\\\funny\\\\FB_IMG_1626020773653.jpg'\n",
      "b'images\\\\funny\\\\Screenshot_20211103_180629.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(100)\n",
    "\n",
    "for file in images_ds.take(5):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['funny', 'not_funny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(images_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(image_count * 0.8)\n",
    "\n",
    "train_ds = images_ds.take(train_size)   # head(train_size)\n",
    "test_ds = images_ds.skip(train_size)    # tail(image_count - train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label = lambda file_path: tf.strings.split(file_path, os.path.sep)[1]\n",
    "\n",
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    \n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'funny', shape=(), dtype=string)\n",
      "tf.Tensor([251.18774 251.18774 251.18774], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(process_image)\n",
    "\n",
    "for image, label in train_ds.take(1):\n",
    "    print(label)\n",
    "    print(image[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'funny', shape=(), dtype=string)\n",
      "tf.Tensor([0.06654412 0.06654412 0.06654412], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(scale)\n",
    "\n",
    "for image, label in train_ds.take(1):\n",
    "    print(label)\n",
    "    print(image[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
